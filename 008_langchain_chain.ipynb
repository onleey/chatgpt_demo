{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onleey/chatgpt_demo/blob/master/008_langchain_chain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "체인이란?\n",
        "- 체인은 여러 개의 LLM이나 프롬프트의 입출력을 연결할 수 있는 모듈이다.\n",
        "- 체인은 프롬프트 템플릿, 모델, 임의의 함수,다른 체인 등으로 구성된다.\n",
        "\n",
        "랭체인에서 제공되는 체인 목록 : 체인은 용도에 따라 크게 세 가지 종류\n",
        "- 제너릭 체인\n",
        "  - LLMChain: 사용자 입력을 기반으로 프롬프트 템플릿으로 프롬프트를 생성해서 LLM을 호출한다.\n",
        "  - SimpleSequentialChain : 입출력이 하나씩 있는 여러 개의 체인을 연결한다.\n",
        "  - SequentialChain : 여러 개의 입출력을 가진 체인을 연결한다.\n",
        "\n",
        "- 인덱스 체인\n",
        "  - RetrievalQA : 질의응답을 수행한다.\n",
        "  - RetrievalQAWithSourcesChain : 소스가 있는 질의응답을 수행한다.\n",
        "  - SummarizeChain : 요약\n",
        "\n",
        "- 유틸리티 체인\n",
        "  - PALChain : 질문을 입력으로 받아 파이썬 코드로 변환하고, 파이썬 REPL을 통해 실행한다.\n",
        "  - SQLDatabaseChain : 데이터베이스에 대한 질문을 입력으로 받아 SQL 쿼리로 변환하고 쿼리를 실행한다.\n",
        "  - LLMMathChain : 수학문제를 입력으로 받아 파이썬 코드로 변환해서 파이썬 REPL로 실행한다.\n",
        "  - LLMBashChain : 질문을 입력으로 받아 bash 명령어로 변환해서 터미널에서 실행한다.\n",
        "  - LLMCheckerChain : 질문을 받고, LLMChain으로 그 질문에 답하고, 다른 LLMChain에서 그 답변을 자체적으로 확인한다.\n",
        "  - LLMRequestsChain : URL과 파라미터 입력을 받아 이를 기반으로 웹 요청을 생성해서 실행한다.\n",
        "  - OpenAIModerationChain : OpenAI의 콘텐츠 모더레이션(moderation) API를 사용한다.\n"
      ],
      "metadata": {
        "id": "4XsJf3HmBsX4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ2KGyLJ99Yi"
      },
      "source": [
        "# 랭체인 사전 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkPbwp6-ploX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d221815-e87d-4148-c948-6fa360e48c8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.0.354\n",
            "  Downloading langchain-0.0.354-py3-none-any.whl (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.3/803.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.354) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.354) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.354) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.354) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.0.354)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.0.354)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.8 (from langchain==0.0.354)\n",
            "  Downloading langchain_community-0.0.8-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.5 (from langchain==0.0.354)\n",
            "  Downloading langchain_core-0.1.6-py3-none-any.whl (208 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.77 (from langchain==0.0.354)\n",
            "  Downloading langsmith-0.0.77-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.354) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.354) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.354) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.354) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.354) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.354) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.354) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.354) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.354) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.354)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.354)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.0.354)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.5->langchain==0.0.354) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.5->langchain==0.0.354) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.354) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.354) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.354) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.354) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.354) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.354) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.5->langchain==0.0.354) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.5->langchain==0.0.354) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.354)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.354 langchain-community-0.0.8 langchain-core-0.1.6 langsmith-0.0.77 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting openai==0.28.1\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.1\n"
          ]
        }
      ],
      "source": [
        "# 패키지 설치\n",
        "!pip install langchain==0.0.354\n",
        "!pip install openai==0.28.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Gf8Rfw2MiG_"
      },
      "outputs": [],
      "source": [
        "# 환경변수 준비\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-T5eel0PlD3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6934d24-7a03-4b74-b79a-409ce05a34d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.2\n"
          ]
        }
      ],
      "source": [
        "# 패키지 설치(소스가 있는 질문과 답변)\n",
        "!pip install faiss-gpu\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPJ2lQW0-J3a"
      },
      "source": [
        "# 제네릭 체인\n",
        "제네릭 체인은 체인을 구축하기 위해 사용하는 체인이다.\n",
        "\n",
        "## LLMChain\n",
        "- LLMChain 은 사용자 입력을 기반으로 프롬프트 템플릿으로 프롬프트를 생성해서 LLM호출을 수행하는 체인이다.\n",
        "- LLMChain( ) 주요 매개변수\n",
        "\n",
        "|매개변수|설명|\n",
        "|---|---|\n",
        "|lim|LLM|\n",
        "|prompt|프롬프트 템플릿|\n",
        "|verbase | 상세정보출력|\n",
        "\n",
        "- verbose=True를 지정하면 내부에서 어떤 처리가 이뤄지고 있는지 출력할 수 있다. 체인은 실행하려면 체인의 predict( )를 호출하고, predict( )의 매개변수에 입력 변수를 지정한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "① LLMChain 사용"
      ],
      "metadata": {
        "id": "ODcgjytXHEAr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJAvf0Xsc8RE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95a63fda-a84c-4753-f8d4-2fe8e2550321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mQ: 기타를 잘 치는 방법은?\n",
            "A:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " 기타를 잘 치는 방법은 많은 연습과 노력이 필요합니다. 먼저 기타를 잘 다루기 위해서는 기본적인 코드와 화음을 익히는 것이 중요합니다. 이를 위해 기타 교본이나 온라인 강의를 활용할 수 있습니다. 또한, 손가락의 움직임과 손목의 자세를 익히는 것도 중요합니다. 이를 위해 기타를 연습할 때는 정확한 자세를 유지하고, 천천히 연습하는 것이 좋습니다. 또한, 다양한 곡을 연습하고 다양한 장르의 음악을 들어보는 것도 도움이 됩니다. 마지막으로, 꾸준한 연습과 열정을 가지고 재미있게 연주하는 것이\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "\n",
        "# 템플릿 생성\n",
        "template = \"\"\"Q: {question}\n",
        "A:\"\"\"\n",
        "\n",
        "# 프롬프트 템플릿 생성\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=template\n",
        ")\n",
        "\n",
        "# LLMChain 생성\n",
        "llm_chain = LLMChain(\n",
        "    llm=OpenAI(temperature=0),\n",
        "    prompt=prompt,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# LLMChain 실행\n",
        "question = \"기타를 잘 치는 방법은?\"\n",
        "print(llm_chain.predict(question=question))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "② 여러 입력 변수를 가진 LLMChain 사용"
      ],
      "metadata": {
        "id": "7uAqNsHLHXz5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXUV97u7c8TS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2306f1d-25f0-45c4-b4f8-104f81b5d694"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m고양이를 주제로 시를 작성해 주세요.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "나는 고양이를 좋아해\n",
            "귀여운 모습에 반해\n",
            "털실로 만든 고양이볼\n",
            "내 마음을 따뜻하게 해\n",
            "\n",
            "고양이는 깜찍한 눈빛\n",
            "매력적인 그 모습에\n",
            "언제나 나를 끌어당겨\n",
            "사랑스러운 친구로\n",
            "\n",
            "낮잠 자는 모습도\n",
            "귀엽고 사랑스러워\n",
            "꼬리를 흔들며 다가와\n",
            "나를 위로해주는 친구\n",
            "\n",
            "고양이야말로 완벽한 동반자\n",
            "나의 곁에서 함께하며\n",
            "언제나 나를 위로해주는\n",
            "나의 사랑스러운 고양이\n"
          ]
        }
      ],
      "source": [
        "# 템플릿 생성\n",
        "template = \"\"\"{subject}를 주제로 {target}를 작성해 주세요.\"\"\"\n",
        "\n",
        "# 프롬프트 템플릿 생성\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"subject\", \"target\"]\n",
        ")\n",
        "\n",
        "# LLMChain 생성\n",
        "llm_chain = LLMChain(\n",
        "    llm=OpenAI(temperature=0),\n",
        "    prompt=prompt,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# LLMChain 실행\n",
        "print(llm_chain.predict(subject=\"고양이\", target=\"시\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0VWNg2mg9yc"
      },
      "source": [
        "## SimpleSequentialChain\n",
        "- SimpleSequentialChain은 입출력이 하나씩 있는 여러 개의 체인을 연결하는 간단한 체인이다."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "① 첫번째 체인 만들기 : 연극의 제목으로 시놉시스를 작성하는 체인"
      ],
      "metadata": {
        "id": "jtGmAwH-H-bc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaUJA0doc8VN"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "\n",
        "# 템플릿 준비\n",
        "template = \"\"\"당신은 극작가입니다. 연극 제목이 주어졌을 때, 그 줄거리를 작성하는 것이 당신의 임무입니다.\n",
        "\n",
        "제목:{title}\n",
        "시놉시스:\"\"\"\n",
        "\n",
        "# 프롬프트 템플릿 준비\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"title\"],\n",
        "    template=template\n",
        ")\n",
        "\n",
        "# LLMChain 준비\n",
        "chain1 = LLMChain(\n",
        "    llm=OpenAI(temperature=0),\n",
        "    prompt=prompt\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "② 두 번째 체인 만들기 : 연극의 시놉시스로부터 리뷰를 작성하는 체인"
      ],
      "metadata": {
        "id": "7CiOrG6MIXHT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABBLfWqZi0ub"
      },
      "outputs": [],
      "source": [
        "# 템플릿 생성\n",
        "template = \"\"\"당신은 연극 평론가입니다. 연극의 시놉시스가 주어지면 그 리뷰를 작성하는 것이 당신의 임무입니다.\n",
        "\n",
        "시놉시스:\n",
        "{synopsis}\n",
        "리뷰:\"\"\"\n",
        "\n",
        "# 프롬프트 템플릿 준비\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"synopsis\"],\n",
        "    template=template\n",
        ")\n",
        "\n",
        "# LLMChain 준비\n",
        "chain2 = LLMChain(\n",
        "    llm=OpenAI(temperature=0),\n",
        "    prompt=prompt\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "③ SimpleSequentialChain 으로 두개의 체인 연결하기\n",
        " - SimpleSequentialChain은 입출력이 1개씩이기 때문에 출력 변수 이름을 지정하지 않고도 연결할 수 있다.\n",
        " - SimpleSequentialChain( ) 주요 매개변수\n",
        "\n",
        "|매개변수|설명|\n",
        "|---|---|\n",
        "|chains|연결할 체인의 배열|\n",
        "|verbose|상세 정보 출력|\n"
      ],
      "metadata": {
        "id": "0hSVDyn-IhpI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auWI2Hj5i0y0"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "\n",
        "# SimpleSequentialChain으로 두 개의 체인을 연결\n",
        "overall_chain = SimpleSequentialChain(\n",
        "    chains=[chain1, chain2],\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "④ SimpleSequentialChain 실행"
      ],
      "metadata": {
        "id": "UZk2isYbJRmo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgRhwV6Qc8XT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87109d11-490d-4cce-fbf7-cf8c19dd685e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m 서울의 도시적인 분위기와 다양한 문화를 담은 랩 뮤지컬\n",
            "\n",
            "서울 랩소디는 서울의 다양한 문화와 도시적인 분위기를 담은 랩 뮤지컬이다. 이 작품은 서울을 배경으로 한 랩 뮤지컬로, 서울의 다양한 지역과 사람들의 이야기를 담고 있다. 서울의 번화한 거리에서는 랩을 통해 도시의 활기와 열정을 느낄 수 있고, 한적한 공원에서는 서울의 자연과 조화로운 면을 느낄 수 있다. 또한 서울의 다양한 문화를 담은 공연장에서는 서울의 다양한 문화를 즐기며 서로 다른 사람들과의\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m\n",
            "서울 랩소디는 도시적인 분위기와 다양한 문화를 담은 랩 뮤지컬로서, 서울의 다양한 지역과 사람들의 이야기를 다채롭게 담고 있습니다. 이 작품은 서울을 배경으로 한 랩 뮤지컬로, 서울의 번화한 거리에서는 랩을 통해 도시의 활기와 열정을 느낄 수 있고, 한적한 공원에서는 서울의 자연과 조화로운 면을 느낄 수 있습니다. 또한 서울의 다양한 문화를 담은 공연장에서는 서울의 다양한 문화를 즐기며 서로 다른 사람들과의 만남을 통해 새로운 경험을 할 수 있습니다.\n",
            "\n",
            "서울 랩소\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "서울 랩소디는 도시적인 분위기와 다양한 문화를 담은 랩 뮤지컬로서, 서울의 다양한 지역과 사람들의 이야기를 다채롭게 담고 있습니다. 이 작품은 서울을 배경으로 한 랩 뮤지컬로, 서울의 번화한 거리에서는 랩을 통해 도시의 활기와 열정을 느낄 수 있고, 한적한 공원에서는 서울의 자연과 조화로운 면을 느낄 수 있습니다. 또한 서울의 다양한 문화를 담은 공연장에서는 서울의 다양한 문화를 즐기며 서로 다른 사람들과의 만남을 통해 새로운 경험을 할 수 있습니다.\n",
            "\n",
            "서울 랩소\n"
          ]
        }
      ],
      "source": [
        "# SimpleSequentialChain 실행\n",
        "print(overall_chain.run(\"서울 랩소디\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgZIDfSgkh0c"
      },
      "source": [
        "## SequentialChain\n",
        "- SequentialChain은 여러 개의 입출력을 가진 체인을 연결하는 체인이다."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "① 첫번째 체인 만들기\n",
        " - 연극의 제목과 시대별 줄거리를 만드는체인이다.\n",
        " - LLMChain의 output_key에 출력 변수명을 지정한다."
      ],
      "metadata": {
        "id": "m-cSYW58JqFC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stYxOZKglZ7U"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "\n",
        "# 템플릿 생성\n",
        "template = \"\"\"당신은 극작가입니다. 극의 제목과 시대적 배경이 주어졌을 때, 그 줄거리를 작성하는 것이 당신의 임무입니다.\n",
        "\n",
        "제목:{title}\n",
        "시대:{era}\n",
        "시놉시스:\"\"\"\n",
        "\n",
        "# 프롬프트 템플릿 생성\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"title\", \"era\"],\n",
        "    template=template\n",
        ")\n",
        "\n",
        "# LLMChain 생성\n",
        "chain1 = LLMChain(\n",
        "    llm=OpenAI(temperature=0),\n",
        "    prompt=prompt,\n",
        "    output_key=\"synopsis\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "② 두 번째 체인 만들기\n",
        "- 첫 번째 체인처럼 연극의 시놉시스로부터 리뷰를 작성하는 체인을 만든다.\n",
        "- LLMChain의 output_key에 출력 변수명을 지정한다."
      ],
      "metadata": {
        "id": "J2o_LtiWJ9gc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yRMJO4DlaAS"
      },
      "outputs": [],
      "source": [
        "# 템플릿 생성\n",
        "template = \"\"\"당신은 연극 평론가입니다. 연극의 시놉시스가 주어지면 그 리뷰를 작성하는 것이 당신의 임무입니다.\n",
        "\n",
        "시놉시스:\n",
        "{synopsis}\n",
        "리뷰:\"\"\"\n",
        "\n",
        "# 프롬프트 템플릿 생성\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"synopsis\"],\n",
        "    template=template\n",
        ")\n",
        "\n",
        "# LLMChain 준비\n",
        "chain2 = LLMChain(\n",
        "    llm=OpenAI(temperature=0),\n",
        "    prompt=prompt,\n",
        "    output_key=\"review\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "③ SequentialChain으로 두개의 체인을 연결\n",
        "- SequentialChain() 주요 매개변수\n",
        "\n",
        "|매개변수|설명|\n",
        "|---|---|\n",
        "|chains|연결할 체인의 배열|\n",
        "|input_variables|입력 변수명의 배열|\n",
        "|output_variables|출력 변수명의 배열|\n",
        "|verbose|상세정보출력|"
      ],
      "metadata": {
        "id": "7UXdJ2zGKWkj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-q1vRpSwmXE5"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "# SequentialChain으로 두 개의 체인을 연결\n",
        "overall_chain = SequentialChain(\n",
        "    chains=[chain1, chain2],\n",
        "    input_variables=[\"title\", \"era\"],\n",
        "    output_variables=[\"synopsis\", \"review\"],\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "④ SequentialChain 실행"
      ],
      "metadata": {
        "id": "GgbgKeG4K2mz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORP8rTN1mXkY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64f8c739-4e09-4c70-ada1-fb93f087168a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'title': '서울 랩소디', 'era': '100년 후의 미래', 'synopsis': '\\n\"서울 랩소디\"는 100년 후의 미래를 배경으로 한 공상과학극이다. 이 시대에는 지구의 자원이 고갈되고 인구가 급증하여 지구는 더 이상 살기 좋은 곳이 아니게 되었다. 그래서 인류는 우주로의 이주를 시작하였고, 지구는 거의 버려진 상태가 되었다.\\n\\n이러한 상황에서도 아직 지구에 남아있는 사람들은 서울에 모여 살고 있다. 그들은 지구를 떠나는 것을 거부하고, 지구를 지키기 위해 싸우는 \\'지구 수호자\\'들이다. 그 중에서도 가장 뛰어난 랩 아티스트인 \\'리플\\'은 지구 수호자들의 리더이자, 지구를 지키는 노', 'review': ' \"서울 랩소디\"는 고갈된 지구에서의 인류의 우주 이주와 지구 수호자들의 이야기를 다룬 공상과학극이다. 이 시대의 지구는 더 이상 살기 좋은 곳이 아니라는 현실을 반영하고 있으며, 이주를 거부하고 지구를 지키기 위해 싸우는 지구 수호자들의 모습은 인류의 희망을 상징한다. 그 중에서도 가장 뛰어난 랩 아티스트인 \\'리플\\'은 지구 수호자들의 리더로서, 지구를 지키는 노력을 보여주며 관객들에게 강한 인상을 남긴다. 고갈된 지구에서의 생존을 위한 인류의 투쟁과 우주 이주의 가능성을 생각하게 '}\n"
          ]
        }
      ],
      "source": [
        "# SequentialChain 실행\n",
        "print(overall_chain({\"title\":\"서울 랩소디\", \"era\": \"100년 후의 미래\"}))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd '/content/drive/MyDrive/chatgpt_api'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GOVx17XMDLI",
        "outputId": "4be0d326-b6bb-4501-f40e-83d733ca5ed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/chatgpt_api\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loLMwgdwdzfW"
      },
      "source": [
        "# 인덱스 체인\n",
        "-  인덱스 체인은 공개되지 않은 개인의 고유 데이터를 이용해 질의응답을 하기 위한 체인이다.\n",
        "- 인덱스 조작을 수행하며, 라마인덱스와 유사한 기능이다.\n",
        "\n",
        "## RetrievalQA\n",
        "- RetrievalQA는 질의응답을 위한 체인이다."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "① 텍스트 로딩 및 청크 분할\n",
        "- 문서를 청크로 분할하려면 CharacterTextSplitter( )를 사용한다.\n",
        "- 확인으 위해 분할개수와 각 청크의 첫 10개 문자와 청크 길이를 표시한다.\n",
        "- CharacterTextSplitter의 처리 흐름\n",
        "  - 구분 기호(기본값은 \"\\n\\n\")로 텍스트를 작은 덩어리로 분할\n",
        "  - 작은 덩어리를 특정 문자 수가 될때까지 병합해서 큰 덩어리를 만든다\n",
        "- CharacterTextSplitter () 주요 매개변수\n",
        "\n",
        "|매개변수|설명|\n",
        "|---|---|\n",
        "|separator|구분 기호|\n",
        "|chunk_size|청크의 최대 문자수|\n",
        "|chunk_overlap|겹치는 최대문자수|"
      ],
      "metadata": {
        "id": "_Dd4q7_4O32N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKAYubWmn-2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74b1ff31-8bb5-4786-b5eb-667c2e75b0c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "제목: '전뇌 빨간 : 299\n",
            "제2장: 울프 코퍼 : 162\n",
            "제3장: 배신과 재 : 273\n",
            "제4장: 울프 코퍼 : 206\n",
            "제5장: 결전의 순 : 294\n",
            "제7장: 새로운 시 : 195\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "# 문서 불러오기(현재 폴더에 문서를 넣어둡니다)\n",
        "with open(\"./data/akazukin_all.txt\") as f:\n",
        "    test_all = f.read()\n",
        "\n",
        "# 청크 분할\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\\n\", # 구분 기호\n",
        "    chunk_size=300, # 청크의 최대 문자 수\n",
        "    chunk_overlap=20 # 겹치는 최대 문자 수\n",
        ")\n",
        "texts = text_splitter.split_text(test_all)\n",
        "\n",
        "# 확인\n",
        "print(len(texts))\n",
        "for text in texts:\n",
        "    print(text[:10], \":\", len(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "② 벡터 데이터베이스 생성\n",
        " - FAISS.from_texts( ) 로 벡터 데이터베이스(Faiss)를 생성한다.\n",
        " - FAISS.from_texts( ) 의 주요 매개변수\n",
        "\n",
        "|매개변수|설명|\n",
        "|---|---|\n",
        "|texts|청크 배열|\n",
        "|embedding|임베딩|\n"
      ],
      "metadata": {
        "id": "XOX36ZXIP4vi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7HiXice6SO-"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores.faiss import FAISS\n",
        "\n",
        "# 벡터 데이터베이스 생성\n",
        "docsearch = FAISS.from_texts(\n",
        "    texts=texts, # 청크 배열\n",
        "    embedding=OpenAIEmbeddings() # 임베딩\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "③ 질의응답 체인 만들기\n",
        "- RetrievalQA.from_chain_type( )의 주요매개변수\n",
        "\n",
        "|매개변수|설명|\n",
        "|---|---|\n",
        "|llm|LLM|\n",
        "|chain_type|체인종류|\n",
        "|retriever|리트리버|\n",
        "\n",
        "- 체인의 종류에 따라 프롬프트에 컨텍스트(질의응답에 활용할 정보)를 추가하는 방법을 선택한다.\n",
        "- 질의응답에서는 stuff, map_reduce, refine,map_rerank의 4가지 중에서 선택할 수 있다.\n",
        "  - staff\n",
        "    - stuff은 모든 관련 데이터를 컨텍스트로 프롬프트에 담아 언어 모델에 전달하는 방식이다.\n",
        "    - 장점은 LLM을 한번만 호출하면 되고, 텍스트 생성시LLM이 한 번에 모든 데이터에 접근할 수 있다. 단점은 LLM에는 컨텍스트 길이 제한이 큰 데이터에는 작동하지 않는다.\n",
        "  \n",
        "  - map_reduce\n",
        "    - map_reduce는 관련 데이터를 청크로 분할하고, 청크별로 프롬프트를 생성해서 LLM을 호출하고, 마지막으로 모든 결과를 결합하는 프롬프트로 LLM을 호출하는 방식이다.\n",
        "    - 장점은 stuff보다 더 큰 데이터에도 작동해서 청크 단위의 LLM 호출을 병렬로 실행할 수 있다. 단점은 stuff 보다 더 많은 LLM 호출이 필요하고,마지막 결합에서 일부 정보가 손실될 수 있다.\n",
        "\n",
        "  - refine\n",
        "    - refine은 관련 데이터를 청크로 나누고, 첫 번째 청크마다 프롬프트를 생성해서 LLM을 호출하고, 그 출력과 함께 다음 청크에서 프롬프트를 생성해서 LLM을 호출하고, 이를 반복하는 방식이다.\n",
        "    - 장점은 좀 더 관련성이 높은 컨텍스트를 가져올 수 있다는 점과 map_reduce보다 손실이 적을 수 있다. 단점은 stuff보다 더 많은 LLM 호출이 필요하고, 청크 LLM 호출을 병렬로 실행할 수 없다.\n",
        "  - map_rerank\n",
        "    - map_rerank는 관련 데이터를 청크로 나누고, 청크마다 프롬프트를 생성해서 LLM을 호출하고, 그 답변이 얼마나 확실한지를 나타내는 점수를 표시하고, 이 점수에 따라 응답의 순위를 매겨 가장 높은 점수를 받은 응답을 반환하는 방식이다.\n",
        "    - 장점은 map_reduce와 유사하며, map_reduce보다 호출 횟수가 적다. 하나의 문서에 하나의 간단한 답변이 있을 때 가장 적합한 방식이다. 단점은 문서 간 정보를 결합할 수 없다.\n",
        "\n"
      ],
      "metadata": {
        "id": "VKg6Xyp_QlEy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgBJjVjLDpFL"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# 질의응답 체인 생성\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=OpenAI(temperature=0), # LLM\n",
        "    chain_type=\"stuff\", # 체인 종류\n",
        "    retriever=docsearch.as_retriever(), # 리트리버\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "④ 질의응답 체인 실행"
      ],
      "metadata": {
        "id": "Vb6pOpROUTdA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFHGEQsQ7u_X"
      },
      "outputs": [],
      "source": [
        "# 질의응답 체인 실행\n",
        "print(qa_chain.run(\"미코의 소꿉친구 이름은?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPVR_OB_E0vp"
      },
      "source": [
        "## RetrievalQAWithSourcesChain\n",
        "- RetrievalQAWithSourcesChain은 소스가 있는 질의응답을 하기 위한 체인이다. 여기서 소스는 질의응답을 할 때 사용한 정보 출처(웹페이지라면 URL, 책이라면 어느 책의 몇 페이지인지 등의 정보)를 의미한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "① 텍스트 로딩 및 청크 분할"
      ],
      "metadata": {
        "id": "VpLqBQiNU4QB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRE7yxXiFV-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5073c350-711e-460a-8db9-ddc155a4b364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "제목: '전뇌 빨간 : 299\n",
            "제2장: 울프 코퍼 : 162\n",
            "제3장: 배신과 재 : 273\n",
            "제4장: 울프 코퍼 : 206\n",
            "제5장: 결전의 순 : 294\n",
            "제7장: 새로운 시 : 195\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "# 문서 로드\n",
        "with open(\"./data/akazukin_all.txt\") as f:\n",
        "    test_all = f.read()\n",
        "\n",
        "# 청크 분할\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\\n\", # 구분 기호\n",
        "    chunk_size=300, # 청크의 최대 문자 수\n",
        "    chunk_overlap=20, # 최대 오버랩 문자 수\n",
        ")\n",
        "texts = text_splitter.split_text(test_all)\n",
        "\n",
        "# 확인\n",
        "print(len(texts))\n",
        "for text in texts:\n",
        "    print(text[:10], \":\", len(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "② 메타데이터 준비\n",
        "- 메타데이터에 각 청크의 정보 출처를 기술한다."
      ],
      "metadata": {
        "id": "fpdplcnPVDco"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fmoKptjFWO5"
      },
      "outputs": [],
      "source": [
        "# 메타데이터 준비\n",
        "metadatas=[\n",
        "    {\"source\": \"1장\"},\n",
        "    {\"source\": \"2장\"},\n",
        "    {\"source\": \"3장\"},\n",
        "    {\"source\": \"4장\"},\n",
        "    {\"source\": \"5~6장\"},\n",
        "    {\"source\": \"7장\"}\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "③ 벡터 데이터베이스 생성\n",
        "- FAISS.from_texts( )의 metadatas에 메타데이터를 지정한다."
      ],
      "metadata": {
        "id": "B4mk0hLRVTcf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLXqPsw8FWSx"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores.faiss import FAISS\n",
        "\n",
        "# 벡터 데이터베이스 생성\n",
        "docsearch = FAISS.from_texts(\n",
        "    texts=texts, # 청크 배열\n",
        "    embedding=OpenAIEmbeddings(), # 임베딩\n",
        "    metadatas=metadatas # 메타데이터\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "④ 소스가 있는 질의응답 체인 만들기"
      ],
      "metadata": {
        "id": "Aythk_FiVgq2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tg2Srbl4Hc8T"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "\n",
        "# 소스가 있는 질의응답 체인 생성\n",
        "qa_chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    llm=OpenAI(temperature=0),\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=docsearch.as_retriever(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⑤ 소스가 있는 질의응답 실행"
      ],
      "metadata": {
        "id": "BdnfZmUuVoeO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5gIi6UYICIQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b351b37-137d-4e76-cff5-9d01f6d89381"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': '미코의 소꿉친구 이름은?', 'answer': ' 미코의 소꿉친구 이름은 료입니다.\\n', 'sources': '2장, 3장'}\n"
          ]
        }
      ],
      "source": [
        "# 소스가 있는 질의응답 체인 실행\n",
        "print(qa_chain({\"question\": \"미코의 소꿉친구 이름은?\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH-1KP49I3nj"
      },
      "source": [
        "# SummarizeChain\n",
        "- SummarizeChain은 요약을 하기 위한 체인이다.\n",
        "- 이것은 특정 클래스 이름이 아니라, load_summarize_chain( )에 요약 체인의 종류를 지정해서 변환되는 요약 체인을 의미한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "① 텍스트 로딩 및 청크 분할"
      ],
      "metadata": {
        "id": "kB3HGXYtWjJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdvQsygSI-dC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9799ca1b-c4d9-48ba-bd89-5d1b13f532b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "제목: '전뇌 빨간 : 299\n",
            "제2장: 울프 코퍼 : 162\n",
            "제3장: 배신과 재 : 273\n",
            "제4장: 울프 코퍼 : 206\n",
            "제5장: 결전의 순 : 294\n",
            "제7장: 새로운 시 : 195\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "# 문서 로드\n",
        "with open(\"./data/akazukin_all.txt\") as f:\n",
        "    test_all = f.read()\n",
        "\n",
        "# 청크 분할\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\\n\", # 구분 기호\n",
        "    chunk_size=300, # 청크의 최대 문자 수\n",
        "    chunk_overlap=20, # 최대 오버랩 문자 수\n",
        ")\n",
        "texts = text_splitter.split_text(test_all)\n",
        "\n",
        "# 확인\n",
        "print(len(texts))\n",
        "for text in texts:\n",
        "    print(text[:10], \":\", len(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "② 청크 배열을 문서로 변환"
      ],
      "metadata": {
        "id": "LRFODKviWsym"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBalbaBGKvnl"
      },
      "outputs": [],
      "source": [
        "from langchain.docstore.document import Document\n",
        "\n",
        "# 청크 배열을 문서 배열로 변환\n",
        "docs = [Document(page_content=t) for t in texts]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "③ 요약 체인 생성\n",
        "- load_summarize_chain( ) 주요 매개변수\n",
        "\n",
        "|매개변수|설명|\n",
        "|---|---|\n",
        "|llm|LLM|\n",
        "|chain_type|체인 종류|\n",
        "\n"
      ],
      "metadata": {
        "id": "S2qBVZEjWw8A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZV6BNPLJHvk"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "# 요약 체인 생성\n",
        "chain = load_summarize_chain(\n",
        "    llm=OpenAI(temperature=0),\n",
        "    chain_type=\"map_reduce\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "④ 요약 체인 실행"
      ],
      "metadata": {
        "id": "YRPtB3siXSOH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vode4HALJkOR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "5e1ee226-e7ac-4d74-8261-ee7c162653a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\"Red Hooded Brain\" is a story about Miko, an illegal data courier, who takes on a mission to expose the corrupt actions of a large corporation. In chapter 2, she evades agents of the corporation and reaches a bar where she meets her childhood friend Ryo. In chapter 3, they team up to expose the corporation\\'s conspiracy and save the citizens. In chapter 4, they engage in a final battle and Miko discovers the corporation\\'s involvement in her mother\\'s illness. In chapter 5, they confront the CEO and expose the corporation\\'s wrongdoings. In chapter 6, they successfully free the citizens and find a cure for Miko\\'s mother\\'s illness. After the corporation\\'s collapse, Miko and Ryo reconcile and vow to use their strength to make the city a better place. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# 요약 체인 실행\n",
        "chain.run(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvCpbUff0eaF"
      },
      "source": [
        "\n",
        "# 유틸리티 체인\n",
        "- 유틸리티 체인은 특정 유틸리티와 연동하기 위한 체인이다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1Pjn2AZw4SZ"
      },
      "source": [
        "## OpenAIModerationChain\n",
        "- OpenAIModerationChain은 LLM의 입출력에 폭력, 자해, 혐오, 성적인 발언 등 문제 발언이 포함돼 있지 않은지(OpenAI의 콘텐츠 정책 준수 여부)를 판단하는 체인이다.\n",
        "-이 체인은 OpenAI API의 Moderation API를 이용한다."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "① OpenAIModerationChain 사용법"
      ],
      "metadata": {
        "id": "cSvkeFrUZp7l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARMSaNZ_0eml"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import OpenAIModerationChain\n",
        "\n",
        "# OpenAIModerationChain 준비\n",
        "chain = OpenAIModerationChain()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "② 문제없는 발언을 시험"
      ],
      "metadata": {
        "id": "weFy6ZfUZv7C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tadNzoXZ2JIY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1a5049f4-c47a-4478-ef45-6908fd53aed6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is OK!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# 문제없는 발언\n",
        "chain.run(\"This is OK!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "③ 문제가 있는 발언을 시험"
      ],
      "metadata": {
        "id": "5m3usWfhZ1h-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyxErTWN2KfV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "748908f1-742f-4723-b0f7-d25b025ad014"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Text was found that violates OpenAI's content policy.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# 문제 발언\n",
        "chain.run(\"I'll kill you!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "④ 문제 발언 시 예외 획득\n",
        "- error=True 매개변수를 지정하면 문제 발언 시 예외를 잡을 수 있다."
      ],
      "metadata": {
        "id": "TNQWxOyuZ6gP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vx5xv5Z72MKZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef0fb1c-9efb-436d-80fd-98f55082b8f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문제 발언입니다!\n",
            "Text was found that violates OpenAI's content policy.\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import OpenAIModerationChain\n",
        "\n",
        "# OpenAIModerationChain 준비\n",
        "chain = OpenAIModerationChain(error=True)\n",
        "\n",
        "try:\n",
        "    # 문제 있는 발언\n",
        "    chain.run(\"I'll kill you!\")\n",
        "except ValueError as e:\n",
        "    print(\"문제 발언입니다!\")\n",
        "    print(e)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}